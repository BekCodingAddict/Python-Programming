{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf19b984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-1.0.8-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting langchain-core<2.0.0,>=1.0.6 (from langchain)\n",
      "  Downloading langchain_core-1.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting langgraph<1.1.0,>=1.0.2 (from langchain)\n",
      "  Using cached langgraph-1.0.3-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\.venv\\lib\\site-packages (from langchain) (2.12.4)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=1.0.6->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core<2.0.0,>=1.0.6->langchain)\n",
      "  Downloading langsmith-0.4.46-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (25.0)\n",
      "Collecting pyyaml<7.0.0,>=5.3.0 (from langchain-core<2.0.0,>=1.0.6->langchain)\n",
      "  Using cached pyyaml-6.0.3-cp313-cp313-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<2.0.0,>=1.0.6->langchain)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (4.15.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.6->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Using cached langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading langgraph_prebuilt-1.0.5-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Using cached langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading xxhash-3.6.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading ormsgpack-1.12.0-cp313-cp313-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting httpx>=0.25.2 (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading orjson-3.11.4-cp313-cp313-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting requests>=2.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain)\n",
      "  Downloading zstandard-0.25.0-cp313-cp313-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting anyio (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting certifi (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain)\n",
      "  Using cached charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl.metadata (38 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Downloading langchain-1.0.8-py3-none-any.whl (93 kB)\n",
      "Downloading langchain_core-1.1.0-py3-none-any.whl (473 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langgraph-1.0.3-py3-none-any.whl (156 kB)\n",
      "Using cached langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
      "Downloading langgraph_prebuilt-1.0.5-py3-none-any.whl (35 kB)\n",
      "Using cached langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Downloading langsmith-0.4.46-py3-none-any.whl (411 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached pyyaml-6.0.3-cp313-cp313-win_amd64.whl (154 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading orjson-3.11.4-cp313-cp313-win_amd64.whl (131 kB)\n",
      "Downloading ormsgpack-1.12.0-cp313-cp313-win_amd64.whl (112 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading xxhash-3.6.0-cp313-cp313-win_amd64.whl (31 kB)\n",
      "Downloading zstandard-0.25.0-cp313-cp313-win_amd64.whl (506 kB)\n",
      "Using cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: zstandard, xxhash, urllib3, tenacity, sniffio, pyyaml, ormsgpack, orjson, jsonpointer, idna, h11, charset_normalizer, certifi, requests, jsonpatch, httpcore, anyio, requests-toolbelt, httpx, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain\n",
      "\n",
      "   ----------------------------------------  0/26 [zstandard]\n",
      "   --- ------------------------------------  2/26 [urllib3]\n",
      "   --- ------------------------------------  2/26 [urllib3]\n",
      "   --- ------------------------------------  2/26 [urllib3]\n",
      "   --- ------------------------------------  2/26 [urllib3]\n",
      "   ---- -----------------------------------  3/26 [tenacity]\n",
      "   ---- -----------------------------------  3/26 [tenacity]\n",
      "   ------ ---------------------------------  4/26 [sniffio]\n",
      "   ------- --------------------------------  5/26 [pyyaml]\n",
      "   ------- --------------------------------  5/26 [pyyaml]\n",
      "   ---------- -----------------------------  7/26 [orjson]\n",
      "   ------------- --------------------------  9/26 [idna]\n",
      "   ------------- --------------------------  9/26 [idna]\n",
      "   --------------- ------------------------ 10/26 [h11]\n",
      "   --------------- ------------------------ 10/26 [h11]\n",
      "   ---------------- ----------------------- 11/26 [charset_normalizer]\n",
      "   ---------------- ----------------------- 11/26 [charset_normalizer]\n",
      "   -------------------- ------------------- 13/26 [requests]\n",
      "   -------------------- ------------------- 13/26 [requests]\n",
      "   --------------------- ------------------ 14/26 [jsonpatch]\n",
      "   ----------------------- ---------------- 15/26 [httpcore]\n",
      "   ----------------------- ---------------- 15/26 [httpcore]\n",
      "   ----------------------- ---------------- 15/26 [httpcore]\n",
      "   ------------------------ --------------- 16/26 [anyio]\n",
      "   ------------------------ --------------- 16/26 [anyio]\n",
      "   ------------------------ --------------- 16/26 [anyio]\n",
      "   ------------------------ --------------- 16/26 [anyio]\n",
      "   ------------------------ --------------- 16/26 [anyio]\n",
      "   -------------------------- ------------- 17/26 [requests-toolbelt]\n",
      "   -------------------------- ------------- 17/26 [requests-toolbelt]\n",
      "   -------------------------- ------------- 17/26 [requests-toolbelt]\n",
      "   --------------------------- ------------ 18/26 [httpx]\n",
      "   --------------------------- ------------ 18/26 [httpx]\n",
      "   --------------------------- ------------ 18/26 [httpx]\n",
      "   ----------------------------- ---------- 19/26 [langsmith]\n",
      "   ----------------------------- ---------- 19/26 [langsmith]\n",
      "   ----------------------------- ---------- 19/26 [langsmith]\n",
      "   ----------------------------- ---------- 19/26 [langsmith]\n",
      "   ----------------------------- ---------- 19/26 [langsmith]\n",
      "   ----------------------------- ---------- 19/26 [langsmith]\n",
      "   ----------------------------- ---------- 19/26 [langsmith]\n",
      "   ------------------------------ --------- 20/26 [langgraph-sdk]\n",
      "   ------------------------------ --------- 20/26 [langgraph-sdk]\n",
      "   -------------------------------- ------- 21/26 [langchain-core]\n",
      "   -------------------------------- ------- 21/26 [langchain-core]\n",
      "   -------------------------------- ------- 21/26 [langchain-core]\n",
      "   -------------------------------- ------- 21/26 [langchain-core]\n",
      "   -------------------------------- ------- 21/26 [langchain-core]\n",
      "   -------------------------------- ------- 21/26 [langchain-core]\n",
      "   -------------------------------- ------- 21/26 [langchain-core]\n",
      "   -------------------------------- ------- 21/26 [langchain-core]\n",
      "   -------------------------------- ------- 21/26 [langchain-core]\n",
      "   -------------------------------- ------- 21/26 [langchain-core]\n",
      "   -------------------------------- ------- 21/26 [langchain-core]\n",
      "   -------------------------------- ------- 21/26 [langchain-core]\n",
      "   -------------------------------- ------- 21/26 [langchain-core]\n",
      "   -------------------------------- ------- 21/26 [langchain-core]\n",
      "   -------------------------------- ------- 21/26 [langchain-core]\n",
      "   --------------------------------- ------ 22/26 [langgraph-checkpoint]\n",
      "   --------------------------------- ------ 22/26 [langgraph-checkpoint]\n",
      "   ----------------------------------- ---- 23/26 [langgraph-prebuilt]\n",
      "   ------------------------------------ --- 24/26 [langgraph]\n",
      "   ------------------------------------ --- 24/26 [langgraph]\n",
      "   ------------------------------------ --- 24/26 [langgraph]\n",
      "   ------------------------------------ --- 24/26 [langgraph]\n",
      "   ------------------------------------ --- 24/26 [langgraph]\n",
      "   ------------------------------------ --- 24/26 [langgraph]\n",
      "   -------------------------------------- - 25/26 [langchain]\n",
      "   -------------------------------------- - 25/26 [langchain]\n",
      "   -------------------------------------- - 25/26 [langchain]\n",
      "   ---------------------------------------- 26/26 [langchain]\n",
      "\n",
      "Successfully installed anyio-4.11.0 certifi-2025.11.12 charset_normalizer-3.4.4 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 jsonpatch-1.33 jsonpointer-3.0.0 langchain-1.0.8 langchain-core-1.1.0 langgraph-1.0.3 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.5 langgraph-sdk-0.2.9 langsmith-0.4.46 orjson-3.11.4 ormsgpack-1.12.0 pyyaml-6.0.3 requests-2.32.5 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 urllib3-2.5.0 xxhash-3.6.0 zstandard-0.25.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e94e3428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## OpenAI API Key and Open Source LLM Llama 3 Gemma2 mistral --Groq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "284eeb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_groq\n",
      "  Downloading langchain_groq-1.0.1-py3-none-any.whl (17 kB)\n",
      "Collecting groq<1.0.0,>=0.30.0\n",
      "  Downloading groq-0.36.0-py3-none-any.whl (137 kB)\n",
      "     ---------------------------------------- 0.0/137.3 kB ? eta -:--:--\n",
      "     ------------------------------------ - 133.1/137.3 kB 2.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- 137.3/137.3 kB 2.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.2 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from langchain_groq) (1.1.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (4.11.0)\n",
      "Requirement already satisfied: sniffio in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (1.3.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (2.12.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (4.15.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (1.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain_groq) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain_groq) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain_groq) (6.0.3)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain_groq) (0.4.46)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain_groq) (9.1.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1.0.0,>=0.30.0->langchain_groq) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1.0.0,>=0.30.0->langchain_groq) (3.11)\n",
      "Requirement already satisfied: certifi in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain_groq) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain_groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain_groq) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.2->langchain_groq) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_groq) (1.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_groq) (3.11.4)\n",
      "Requirement already satisfied: requests>=2.0.0 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_groq) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_groq) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain_groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain_groq) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain_groq) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_groq) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\python\\python-programming\\complete_agentic_ai_bootcamp_with_langgraph_and_langchain\\section_7_lcel\\venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_groq) (2.3.0)\n",
      "Installing collected packages: groq, langchain_groq\n",
      "Successfully installed groq-0.36.0 langchain_groq-1.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_groq\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86c3b36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<groq.resources.chat.completions.Completions object at 0x0000025AFCCD2890> async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000025A92911090> model_name='openai/gpt-oss-20b' model_kwargs={} groq_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model=ChatGroq(model=\"openai/gpt-oss-20b\",groq_api_key=groq_api_key)\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f238ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='안녕하세요, 어떻게 지내세요?' additional_kwargs={'reasoning_content': 'We need to translate \"Hello, how are you?\" to Korean. The user says \"Hello, how are you?\" We need to translate that. The instruction: \"Translate the following text to Koreann\". Probably means Korean. The translation: \"안녕하세요, 어떻게 지내세요?\" Or \"안녕, 어떻게 지내?\" The polite form: \"안녕하세요, 어떻게 지내세요?\" The user didn\\'t specify formality. A safe polite. So output that.'} response_metadata={'token_usage': {'completion_tokens': 113, 'prompt_tokens': 87, 'total_tokens': 200, 'completion_time': 0.11387315, 'completion_tokens_details': {'reasoning_tokens': 96}, 'prompt_time': 0.004676563, 'prompt_tokens_details': None, 'queue_time': 0.051258686, 'total_time': 0.118549713}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e99e93f2ac', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--6bb96bb9-ff69-4491-b429-eb62d7ae7fc6-0' usage_metadata={'input_tokens': 87, 'output_tokens': 113, 'total_tokens': 200, 'output_token_details': {'reasoning': 96}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages=[\n",
    "    SystemMessage(content=\"Translate the following text to Korean.\"),\n",
    "    HumanMessage(content=\"Hello, how are you?\")\n",
    "]\n",
    "\n",
    "response=model.invoke(messages)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cda2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요, 어떻게 지내세요?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser=StrOutputParser()\n",
    "\n",
    "result=parser.invoke(response)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3836acfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 어떻게 지내세요?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Using LCEL - chain of components\n",
    "chain=model|parser\n",
    "chain.invoke(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fc4e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following text to Korean.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hello, how are you?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Prompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "generic_template=\"Translate the following text to {language}.\"\n",
    "prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",generic_template),\n",
    "    (\"human\",\"{text}\")\n",
    "])\n",
    "\n",
    "result=prompt.invoke({\"language\":\"Korean\",\"text\":\"Hello, how are you?\"})\n",
    "result.to_messages()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da00c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 어떻게 지내세요?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## CHaining together components with LCEL\n",
    "chain=prompt|model|parser\n",
    "chain.invoke({\"language\":\"Korean\",\"text\":\"Hello, how are you?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
