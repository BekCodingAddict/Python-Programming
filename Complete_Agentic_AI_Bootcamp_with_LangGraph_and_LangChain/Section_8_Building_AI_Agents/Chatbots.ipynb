{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f17282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41a8e735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Python-Programming\\Complete_Agentic_AI_Bootcamp_with_LangGraph_and_LangChain\\Section_8_Building_AI_Agents\\venv\\lib\\site-packages\\pydantic\\main.py:250: UserWarning: WARNING! top_p is not default parameter.\n",
      "                    top_p was transferred to model_kwargs.\n",
      "                    Please confirm that top_p is what you intended.\n",
      "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 32768, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x00000190FE5B7E80>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000190FE5B6FE0>, model_name='openai/gpt-oss-20b', temperature=0.5, model_kwargs={'top_p': 0.95}, groq_api_key=SecretStr('**********'), max_tokens=8192)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(\n",
    "    model_name=\"openai/gpt-oss-20b\",\n",
    "    api_key=groq_api_key,\n",
    "    temperature=0.5,\n",
    "    max_tokens=8192,\n",
    "    top_p=0.95,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9060821c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! Iâ€™m doing greatâ€”thanks for asking. How about you? Anything interesting on your mind today?', additional_kwargs={'reasoning_content': 'We need to respond as ChatGPT. The user says \"Hello, how are you?\" It\\'s a greeting. We should respond politely, perhaps ask how they are. No constraints.'}, response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 77, 'total_tokens': 145, 'completion_time': 0.066662205, 'completion_tokens_details': {'reasoning_tokens': 37}, 'prompt_time': 0.003688563, 'prompt_tokens_details': None, 'queue_time': 0.197960157, 'total_time': 0.070350768}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e23fc997ca', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--cdfcd242-c874-4f10-a9aa-e0ddb1b4d540-0', usage_metadata={'input_tokens': 77, 'output_tokens': 68, 'total_tokens': 145, 'output_token_details': {'reasoning': 37}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hello, how are you?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01b4c77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You mentioned that your name is **John\\u202fDoe**, youâ€™re **30\\u202fyears old**, and you live in **San\\u202fFrancisco**.', additional_kwargs={'reasoning_content': \"User wants to know their name, age, and location. According to policy, we can provide that because it's user-provided data. It's not sensitive. So we can answer.\"}, response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 135, 'total_tokens': 211, 'completion_time': 0.096444218, 'completion_tokens_details': {'reasoning_tokens': 37}, 'prompt_time': 0.223708177, 'prompt_tokens_details': None, 'queue_time': 0.362933045, 'total_time': 0.320152395}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_24bfb4a850', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--25d70e2d-0fc9-4fd0-a938-966046e305af-0', usage_metadata={'input_tokens': 135, 'output_tokens': 76, 'total_tokens': 211, 'output_token_details': {'reasoning': 37}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([\n",
    "    HumanMessage(content=\"Hello, My name is John Doe.I am a software engineer.I am 30 years old.I live in San Francisco.I am a good person.\"),\n",
    "    AIMessage(content=\"Hello, John Doe. How can I help you today?\"),\n",
    "    HumanMessage(content=\"Hey What is my name and age? Where do I live?\")\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cde91ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afcd17f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hi John! ðŸ‘‹ Itâ€™s great to meet a fellow software engineer from San\\u202fFrancisco. How can I help you today? Whether youâ€™re looking for coding tips, project ideas, or just want to chat about the latest tech trends, Iâ€™m here for you!', additional_kwargs={'reasoning_content': 'The user says: \"Hello, My name is John Doe. I am a software engineer. I am 30 years old. I live in San Francisco. I am a good person.\" They are basically introducing themselves. We need to respond. There\\'s no explicit request. We can respond with a friendly greeting, maybe ask follow-up. We should maintain conversation. Also we might reflect back some of the info. No conflict. Just respond.'}, response_metadata={'token_usage': {'completion_tokens': 153, 'prompt_tokens': 100, 'total_tokens': 253, 'completion_time': 0.160138931, 'completion_tokens_details': {'reasoning_tokens': 89}, 'prompt_time': 0.006696352, 'prompt_tokens_details': None, 'queue_time': 0.047710078, 'total_time': 0.166835283}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e99e93f2ac', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--e8904df0-567d-4fba-8f7c-5f51b9bde6ba-0', usage_metadata={'input_tokens': 100, 'output_tokens': 153, 'total_tokens': 253, 'output_token_details': {'reasoning': 89}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "with_message_history.invoke(\n",
    "    HumanMessage(content=\"Hello, My name is John Doe.I am a software engineer.I am 30 years old.I live in San Francisco.I am a good person.\"),\n",
    "    config=config\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64d11e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Youâ€™re John\\u202fDoe, 30\\u202fyears old, and you live in San\\u202fFrancisco.', additional_kwargs={'reasoning_content': 'We need to respond with the information the user provided: name John Doe, age 30, live in San Francisco. Probably just repeat that.'}, response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 178, 'total_tokens': 238, 'completion_time': 0.061163478, 'completion_tokens_details': {'reasoning_tokens': 30}, 'prompt_time': 0.014832029, 'prompt_tokens_details': None, 'queue_time': 0.051878731, 'total_time': 0.075995507}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e99e93f2ac', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--ec0e3fb7-3bcf-4d21-bc41-da70dceb509f-0', usage_metadata={'input_tokens': 178, 'output_tokens': 60, 'total_tokens': 238, 'output_token_details': {'reasoning': 30}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    HumanMessage(content=\"Hey What is my name and age? Where do I live?\"),\n",
    "    config=config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "003783a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Iâ€™m sorry, but I donâ€™t have any information about your name or age. If youâ€™d like to share that, I can keep it in mind for our conversation!', additional_kwargs={'reasoning_content': 'User asks: \"What is my name and age?\" We don\\'t have that info. According to policy, we must not guess or fabricate. We should ask for clarification or say we don\\'t know. So we should respond politely that we don\\'t have that information.'}, response_metadata={'token_usage': {'completion_tokens': 96, 'prompt_tokens': 78, 'total_tokens': 174, 'completion_time': 0.10049759, 'completion_tokens_details': {'reasoning_tokens': 52}, 'prompt_time': 0.005111536, 'prompt_tokens_details': None, 'queue_time': 0.053361864, 'total_time': 0.105609126}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e99e93f2ac', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--8948b448-6905-498c-a05b-1a32afaa1ec2-0', usage_metadata={'input_tokens': 78, 'output_tokens': 96, 'total_tokens': 174, 'output_token_details': {'reasoning': 52}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Changing session id\n",
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response = with_message_history.invoke(\n",
    "    HumanMessage(content=\"What is my name and age?\"),\n",
    "    config=config1\n",
    ")\n",
    "\n",
    "response\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02aaedfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Got itâ€”John, 30\\u202fyears old, San\\u202fFrancisco, and a good person! How can I help you today?', additional_kwargs={'reasoning_content': 'User repeats same statement. Likely wants confirmation or maybe wants something else. We should respond acknowledging. Possibly ask what they want.'}, response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 211, 'total_tokens': 275, 'completion_time': 0.064407667, 'completion_tokens_details': {'reasoning_tokens': 27}, 'prompt_time': 0.01437326, 'prompt_tokens_details': None, 'queue_time': 0.017987668, 'total_time': 0.078780927}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_d23c14756c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--a17a73a4-d48e-4aab-95be-a69ace05e0c8-0', usage_metadata={'input_tokens': 211, 'output_tokens': 64, 'total_tokens': 275, 'output_token_details': {'reasoning': 27}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    HumanMessage(content=\"Hey My name is John Doe.I am 30 years old.I live in San Francisco.I am a good person.\"),\n",
    "    config=config1\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8461995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is **John\\u202fDoe** and youâ€™re **30\\u202fyears old**.', additional_kwargs={'reasoning_content': 'The user repeats question. We have to answer with name and age. We should not mention policy. Just answer.'}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 291, 'total_tokens': 342, 'completion_time': 0.049989025, 'completion_tokens_details': {'reasoning_tokens': 24}, 'prompt_time': 0.014088099, 'prompt_tokens_details': None, 'queue_time': 0.019329709, 'total_time': 0.064077124}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_5979a0e1b7', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--4206971a-3e75-47a7-9534-e5992dcc6730-0', usage_metadata={'input_tokens': 291, 'output_tokens': 51, 'total_tokens': 342, 'output_token_details': {'reasoning': 24}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    HumanMessage(content=\"What is my name and age?\"),\n",
    "    config=config1\n",
    ")\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
